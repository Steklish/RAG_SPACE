# RAG AI-приложение (RAGgie BOY) - Технологический обзор

## Основные технологии

### Backend
- **FastAPI** - веб-фреймворк для создания API с автоматической документацией
- **Python 3.x** - основной язык программирования для бэкенда
- **llama-cpp-python** - для запуска локальных LLM моделей (llama.cpp)
- **ChromaDB** - векторная база данных для хранения эмбеддингов документов
- **Pydantic** - валидация данных и создание схем данных
- **Requests/HTTPX** - для HTTP-запросов к внешним API и локальным серверам
- **pdfplumber** - для извлечения текста из PDF-документов
- **python-docx** - для извлечения текста из DOCX-документов
- **BeautifulSoup** - для извлечения текста из HTML-документов
- **chardet** - для определения кодировки текстовых файлов
- **Unstructured** - для извлечения текста из различных форматов документов
- **PyMuPDF** - альтернативный инструмент для работы с PDF
- **tiktoken** - для токенизации текста

### Frontend
- **React** - библиотека для создания пользовательского интерфейса
- **Vite** - инструмент сборки для быстрой разработки
- **CSS** - для стилизации интерфейса
- **Vite-based React application** - в директории front-react-v/

### Модели и ИИ
- **Gemma-2B-it-Q4_K_S.gguf** - чат-модель для генерации ответов (локально)
- **embeddinggemma-300m-qat-Q8_0.gguf** - модель для создания текстовых эмбеддингов (локально)
- **llama.cpp** - фреймворк для запуска моделей на CPU/GPU
- **Google Gemini API** - поддержка облачных моделей (опционально)
- **OpenRouter Qwen API** - поддержка облачных моделей (опционально)

## Архитектурные подходы

### RAG (Retrieval-Augmented Generation)
- **Документ-ориентированный подход**: пользователи могут загружать документы различных форматов (PDF, DOCX, HTML, текстовые файлы), которые разбиваются на чанки, векторизуются и хранятся в ChromaDB
- **Контекстное извлечение**: агент определяет необходимость извлечения информации и ищет релевантные фрагменты в загруженных документах
- **Интент-анализ**: система анализирует намерения пользователя и определяет необходимость поиска в документах или базе данных
- **Поддержка SQL-запросов**: дополнительная функциональность для работы с SQL-базами данных через встроенный MCP-сервер

### Модульная архитектура
- **Generator**: абстракция над различными LLM-бэкендами (Qwen, Llama, Gemini) с возможностью переключения между ними
- **ChromaClient**: управление векторной базой данных ChromaDB с поддержкой метаданных
- **EmbeddingClient**: создание векторных эмбеддингов текста через локальный сервер
- **ThreadStore**: хранение истории чатов в файловой системе
- **Agent**: центральный компонент, координирующий все операции - анализ намерений, извлечение, генерация
- **ServerLauncher**: автоматический запуск и управление локальными LLM-серверами

### Безопасность и конфиденциальность
- **Локальная обработка**: все данные обрабатываются на локальных серверах без отправки в облако (по умолчанию)
- **Изоляция данных**: документы и эмбеддинги хранятся локально в векторной базе
- **Контроль пользовательских данных**: пользователь полностью контролирует свои документы и чаты
- **Поддержка облачных API**: опционально можно использовать облачные модели через API

## Структура проекта

### Директории
- **app/** - основной бэкенд-сервер на Python
- **front-react-v/** - React-фронтенд
- **models/** - директория для хранения LLM-моделей
- **storage/** - директория для хранения:
  - **raw/** - загруженные документы
  - **threads/** - файлы с историей чатов
  - **chroma/** - векторная база данных ChromaDB
  - **dev/** - файлы для отладки

### Основные компоненты бэкенда

#### 1. app/main.py
- Точка входа для FastAPI-приложения
- Инициализация всех глобальных зависимостей
- Настройка CORS middleware
- Подключение контроллеров API
- Определение глобальных конфигурационных параметров

#### 2. app/agent.py
- Основной интеллектуальный агент системы
- Анализ намерений пользователя
- Решение о необходимости извлечения информации
- Генерация ответов с учетом контекста
- Поддержка итеративного поиска информации
- Поддержка SQL-запросов к базам данных (через MCP)

#### 3. app/chroma_client.py
- Клиент для работы с ChromaDB
- Индексация документов с разбиением на чанки
- Поиск релевантных фрагментов с фильтрацией по документам
- Управление метаданными документов
- Поддержка добавления/удаления документов

#### 4. app/generator.py
- Абстракция для работы с различными LLM-бэкендами
- Поддержка локальных (llama.cpp) и облачных (Qwen, Gemini) моделей
- JSON-валидация через Pydantic-схемы
- Обработка ошибок и повторные попытки
- Поддержка структурированной генерации

#### 5. app/embedding_client.py
- Клиент для генерации текстовых эмбеддингов
- Поддержка батчинга для повышения производительности
- Интеграция с локальным сервером эмбеддингов

#### 6. app/thread_store.py
- Хранение истории чатов в файловой системе
- Управление сессиями пользователей
- Привязка документов к чатам
- Операции с сообщениями (удаление, обновление)

#### 7. app/ingest.py
- Извлечение текста из различных форматов документов
- Поддержка PDF, DOCX, HTML, текстовых файлов
- Интеллектуальная токенизация и разбиение на чанки
- Нормализация текста и удаление гиперссылок

#### 8. app/server_launcher.py
- Автоматический запуск локальных серверов моделей
- Управление конфигурациями запуска
- Мониторинг состояния серверов
- Поддержка нескольких конфигураций для одной модели

## API контроллеры

### 1. Document Controller (document_controller.py)
- `/api/documents/` - загрузка документов
- `/api/documents/` - получение списка документов
- `/api/documents/{doc_id}` - получение документа по ID
- `/api/documents/{doc_id}` - удаление документа
- `/api/documents/chunks` - поисковый запрос в чанках документов

### 2. Thread Controller (thread_controller.py)
- `/api/threads/` - создание и получение списка чатов
- `/api/threads/{thread_id}` - получение конкретного чата
- `/api/threads/{thread_id}/details` - детали чата
- `/api/threads/{thread_id}/metadata` - обновление метаданных
- `/api/threads/{thread_id}/rename` - переименование чата
- `/api/threads/{thread_id}/chat` - чат с агентом (стрииминг)
- `/api/threads/{thread_id}/documents` - привязка документа к чату

### 3. Settings Controller (settings_controller.py)
- `/api/settings/` - получение/обновление настроек
- `/api/settings/server_urls` - URL-адреса серверов
- `/api/settings/launch_configs` - конфигурации запуска
- `/api/settings/launch_configs/{config_name}` - управление конкретной конфигурацией

### 4. Server Controller (server_controller.py)
- `/api/servers/configs` - доступные конфигурации серверов
- `/api/servers/start` - запуск сервера
- `/api/servers/stop` - остановка сервера
- `/api/servers/update_config` - обновление конфигурации
- `/api/servers/status` - статус запущенных серверов
- `/api/servers/active_configs` - активные конфигурации

### 5. Util Controller (util_controller.py)
- `/api/status` - проверка статуса системы
- `/api/chat_model` - информация о чат-модели
- `/api/embedding_model` - информация о модели эмбеддингов
- `/api/get_loaded_models` - список загруженных моделей

## Ключевые функции

### 1. Загрузка и индексация документов
- Поддержка PDF, DOCX, HTML, текстовых файлов
- Автоматическое определение типов файлов
- Дедупликация документов по хешу
- Разбиение на чанки с перекрытием
- Сохранение метаданных

### 2. Поиск по документам
- Векторный поиск с использованием семантической близости
- Фильтрация по конкретным документам
- Поддержка фильтров при поиске
- Возврат релевантных чанков с метаданными

### 3. Чат с контекстом
- Поддержка стриминга ответов
- Генерация ответов с учетом истории чата
- Цитирование источников при использовании документации
- Поддержка нескольких языков

### 4. Управление чатами
- Создание, переименование и удаление чатов
- Привязка и отвязка документов от чатов
- Управление историей сообщений
- Сохранение чатов в файловой системе

### 5. Поддержка SQL-запросов
- Интеграция с внешними SQL-базами данных
- Генерация SQL-запросов на основе естественного языка
- Обработка UNION-запросов
- Безопасность SQL-запросов (ограничение опасных операций)

## Конфигурационные параметры

### Основные переменные окружения
- `STORAGE_RAW_DIR` - директория хранения загруженных файлов
- `CHROMA_PERSIST_DIR` - директория хранения ChromaDB
- `CHUNK_SIZE` - размер чанка при индексации (по умолчанию 800)
- `CHUNK_OVERLAP` - перекрытие чанков (по умолчанию 120)
- `TOP_K` - количество возвращаемых результатов по умолчанию (4)
- `MAX_CONTEXT_CHARS` - максимальное количество символов в контексте (12000)
- `LLAMACPP_CHAT_BASE` - URL чат-сервера llama.cpp (11434)
- `LLAMACPP_EMBED_BASE` - URL сервера эмбеддингов (11435)
- `LLAMACPP_TIMEOUT_S` - таймаут для llama.cpp запросов (300 секунд)
- `LLAMACPP_MAX_RETRIES` - максимальное количество попыток (3)
- `USE_GEMINI` - использовать Google Gemini API (0/1)
- `USE_QWEN` - использовать Qwen API через OpenRouter (0/1)
- `GEMINI_API_KEY` - API-ключ для Google Gemini
- `QWEN_TOKEN` - API-токен для Qwen через OpenRouter
- `MCP_PORT` - порт для MCP-сервера (по умолчанию 1234)
- `START_SERVERS` - автоматический запуск серверов моделей (true/false)

### Конфигурации запуска моделей
- `app/launch_configs/chat_server.json` - конфигурации для чат-модели
- `app/launch_configs/embedding_server.json` - конфигурации для модели эмбеддингов
- Поддержка нескольких конфигураций для одной модели
- Возможность переключения между различными моделями

## Особенности реализации

### 1. Автозапуск серверов моделей
- Приложение может автоматически запускать локальные серверы моделей
- Поддержка нескольких конфигураций для каждой модели
- Мониторинг состояния запущенных процессов
- Возможность остановки и перезапуска серверов через API

### 2. Управление конфигурациями
- Гибкая настройка моделей через JSON-файлы
- Возможность динамического обновления конфигураций
- Поддержка нескольких вариантов одной модели
- Автоматическое переключение между конфигурациями

### 3. Интеграция с базой данных
- Дополнительная поддержка SQL-запросов к внешним базам данных
- Генерация SQL-запросов на основе естественного языка
- Безопасность SQL-запросов с защитой от SQL-инъекций
- Поддержка UNION-запросов с безопасной обработкой

### 4. Итеративный поиск
- Система может самостоятельно искать дополнительную информацию, если первый ответ неполный
- Максимальное количество итераций ограничено (по умолчанию 3)
- Поддержка цитирования источников для каждого фрагмента информации

### 5. Метаданные и трассировка
- Все операции сопровождаются метаданными и ссылками на исходные документы
- Сохранение истории чатов с полной информацией о retrieved documents
- Поддержка цитирования источников в формате Markdown
- Отслеживание состояния и прогресса операций

### 6. Поддержка разных LLM-бэкендов
- Единый интерфейс для работы с локальными и облачными моделями
- Поддержка llama.cpp, Google Gemini и OpenRouter Qwen
- Автоматическое определение типа бэкенда
- Возможность переключения между бэкендами в рантайме

### 7. Система типов и валидации
- Полная типизация через Pydantic-модели
- Валидация всех входных и выходных данных
- Генерация JSON-ответов, соответствующих схемам
- Обработка ошибок на уровне типов

### 8. Безопасность и обработка ошибок
- Защита от потенциально вредоносных SQL-запросов
- Обработка некорректных вводов пользователей
- Повторные попытки при ошибках соединения
- Изоляция контекста между разными чатами